{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional if you are using a GPU\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Model\n",
    "model = hub.load('https://tfhub.dev/google/movenet/multipose/lightning/1')\n",
    "movenet = model.signatures['serving_default']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw edges\n",
    "EDGES = {\n",
    "    (0, 1): 'm',\n",
    "    (0, 2): 'c',\n",
    "    (1, 3): 'm',\n",
    "    (2, 4): 'c',\n",
    "    (0, 5): 'm',\n",
    "    (0, 6): 'c',\n",
    "    (5, 7): 'm',\n",
    "    (7, 9): 'm',\n",
    "    (6, 8): 'c',\n",
    "    (8, 10): 'c',\n",
    "    (5, 6): 'y',\n",
    "    (5, 11): 'm',\n",
    "    (6, 12): 'c',\n",
    "    (11, 12): 'y',\n",
    "    (11, 13): 'm',\n",
    "    (13, 15): 'm',\n",
    "    (12, 14): 'c',\n",
    "    (14, 16): 'c'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw the keypoints on the human subject\n",
    "def draw_keypoints(frame, keypoints, confidence_threshold):\n",
    "    y, x, c = frame.shape\n",
    "    shaped = np.squeeze(np.multiply(keypoints, [y,x,1]))\n",
    "    \n",
    "    for kp in shaped:\n",
    "        ky, kx, kp_conf = kp\n",
    "        if kp_conf > confidence_threshold:\n",
    "            cv2.circle(frame, (int(kx), int(ky)), 6, (0,255,0), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to loop through each person detected and render\n",
    "def loop_through_people(frame, keypoints_with_scores, edges, confidence_threshold):\n",
    "    for person in keypoints_with_scores:\n",
    "        draw_connections(frame, person, edges, confidence_threshold)\n",
    "        draw_keypoints(frame, person, confidence_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw connectors(lines from joints)\n",
    "def draw_connections(frame, keypoints, edges, confidence_threshold):\n",
    "    y, x, c = frame.shape\n",
    "    shaped = np.squeeze(np.multiply(keypoints, [y,x,1]))\n",
    "    \n",
    "    for edge, color in edges.items():\n",
    "        p1, p2 = edge\n",
    "        y1, x1, c1 = shaped[p1]\n",
    "        y2, x2, c2 = shaped[p2]\n",
    "        \n",
    "        if (c1 > confidence_threshold) & (c2 > confidence_threshold):      \n",
    "            cv2.line(frame, (int(x1), int(y1)), (int(x2), int(y2)), (0,0,255), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run this just to view the video with the keypoint and edges\n",
    "cap = cv2.VideoCapture(r\"C:\\Users\\ayesh\\Downloads\\Yaish\\Fullfoul\\selfshot_video_1.mp4\")\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "        \n",
    "    if not ret:\n",
    "        break\n",
    "        \n",
    "    # Resize image\n",
    "    img = frame.copy()\n",
    "    img = tf.image.resize_with_pad(tf.expand_dims(img, axis=0), 384,640)\n",
    "    input_img = tf.cast(img, dtype=tf.int32)\n",
    "    \n",
    "    # Detection section\n",
    "    results = movenet(input_img)\n",
    "    keypoints_with_scores = results['output_0'].numpy()[:,:,:51].reshape((6,17,3))\n",
    "    \n",
    "    # Render keypoints \n",
    "    loop_through_people(frame, keypoints_with_scores, EDGES, 0.1)\n",
    "    \n",
    "    cv2.imshow('Movenet Multipose', frame)\n",
    "    \n",
    "    if cv2.waitKey(10) & 0xFF==ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.4466518 , 0.8612912 , 0.32815337],\n",
       "        [0.43496653, 0.8580613 , 0.36712667],\n",
       "        [0.43250212, 0.8611075 , 0.40836304],\n",
       "        [0.41552076, 0.86621284, 0.46887434],\n",
       "        [0.40377066, 0.8816418 , 0.4177208 ],\n",
       "        [0.4478281 , 0.88256806, 0.6443066 ],\n",
       "        [0.42883858, 0.95933545, 0.44161174],\n",
       "        [0.5461881 , 0.8564455 , 0.5259613 ],\n",
       "        [0.55058146, 0.9550271 , 0.15743777],\n",
       "        [0.5798087 , 0.8034275 , 0.32677203],\n",
       "        [0.63623405, 0.9242259 , 0.09693617],\n",
       "        [0.6640478 , 0.9469134 , 0.35237807],\n",
       "        [0.6678417 , 0.9929147 , 0.6908403 ],\n",
       "        [0.8372962 , 0.8682291 , 0.1604816 ],\n",
       "        [0.83449996, 0.98304504, 0.0901176 ],\n",
       "        [0.9654872 , 0.86400414, 0.04105417],\n",
       "        [0.972891  , 0.9850193 , 0.04833445]],\n",
       "\n",
       "       [[0.45305008, 0.7461603 , 0.21939935],\n",
       "        [0.4370154 , 0.7451717 , 0.23444988],\n",
       "        [0.43648058, 0.74688786, 0.2825412 ],\n",
       "        [0.41049808, 0.7275561 , 0.39465514],\n",
       "        [0.41217992, 0.72689563, 0.5651567 ],\n",
       "        [0.44549876, 0.687921  , 0.6136885 ],\n",
       "        [0.45031938, 0.68989193, 0.4795078 ],\n",
       "        [0.5502897 , 0.7298249 , 0.39960834],\n",
       "        [0.554584  , 0.7333024 , 0.60445553],\n",
       "        [0.4803205 , 0.7517361 , 0.26989752],\n",
       "        [0.4701434 , 0.752723  , 0.5812183 ],\n",
       "        [0.6635972 , 0.6749124 , 0.65481937],\n",
       "        [0.66830504, 0.6999725 , 0.67491525],\n",
       "        [0.82921576, 0.6850663 , 0.64896435],\n",
       "        [0.82988447, 0.7308118 , 0.61994916],\n",
       "        [0.965795  , 0.65724176, 0.44915438],\n",
       "        [0.9637532 , 0.65746087, 0.10546251]],\n",
       "\n",
       "       [[0.4752208 , 0.25339046, 0.28054658],\n",
       "        [0.46524593, 0.2509113 , 0.3425306 ],\n",
       "        [0.47022492, 0.24934803, 0.28174636],\n",
       "        [0.4629875 , 0.24688785, 0.25587243],\n",
       "        [0.48436606, 0.24489693, 0.25991422],\n",
       "        [0.47257054, 0.26575324, 0.28086862],\n",
       "        [0.51525587, 0.2594494 , 0.23692702],\n",
       "        [0.46612602, 0.28314623, 0.14674796],\n",
       "        [0.5285735 , 0.27275345, 0.1536762 ],\n",
       "        [0.4672309 , 0.25647643, 0.1075789 ],\n",
       "        [0.52904415, 0.26324072, 0.15516305],\n",
       "        [0.45592138, 0.31256914, 0.26948327],\n",
       "        [0.47682786, 0.31237015, 0.28409955],\n",
       "        [0.45255202, 0.33891046, 0.18578844],\n",
       "        [0.48259968, 0.33884713, 0.15035374],\n",
       "        [0.472318  , 0.36698958, 0.07375647],\n",
       "        [0.47468424, 0.36295694, 0.10043639]],\n",
       "\n",
       "       [[0.10954636, 0.15014799, 0.10422296],\n",
       "        [0.10871967, 0.15064023, 0.11279831],\n",
       "        [0.10780725, 0.1488985 , 0.10738954],\n",
       "        [0.10927555, 0.14993952, 0.09659109],\n",
       "        [0.10742678, 0.14641947, 0.08864936],\n",
       "        [0.11574733, 0.15147398, 0.0735948 ],\n",
       "        [0.10995336, 0.14429604, 0.0550296 ],\n",
       "        [0.10522512, 0.15828353, 0.13152122],\n",
       "        [0.09870648, 0.14732015, 0.09724165],\n",
       "        [0.10874549, 0.1540617 , 0.24050626],\n",
       "        [0.10818638, 0.1487702 , 0.19210707],\n",
       "        [0.1378923 , 0.15184528, 0.07748448],\n",
       "        [0.13687854, 0.14806688, 0.10077702],\n",
       "        [0.11453556, 0.15453887, 0.0447049 ],\n",
       "        [0.11383652, 0.146782  , 0.05803242],\n",
       "        [0.11627406, 0.15298909, 0.05518308],\n",
       "        [0.11711419, 0.14780644, 0.06932312]],\n",
       "\n",
       "       [[0.17782342, 0.99168605, 0.00638435],\n",
       "        [0.17495885, 0.9912427 , 0.00379637],\n",
       "        [0.17636488, 0.9903067 , 0.00269459],\n",
       "        [0.17714095, 0.99023116, 0.00351975],\n",
       "        [0.17888008, 0.98862785, 0.00571674],\n",
       "        [0.18448512, 0.9917197 , 0.00657564],\n",
       "        [0.1834157 , 0.99146384, 0.00584108],\n",
       "        [0.18521434, 0.9915147 , 0.00436482],\n",
       "        [0.18007529, 0.99785537, 0.00315247],\n",
       "        [0.1851009 , 0.9921509 , 0.00548211],\n",
       "        [0.18570164, 0.99958134, 0.00497209],\n",
       "        [0.20301235, 0.9947978 , 0.00267576],\n",
       "        [0.20917301, 0.9934557 , 0.01160149],\n",
       "        [0.21199904, 0.9890057 , 0.00652273],\n",
       "        [0.18950284, 0.99883366, 0.00378349],\n",
       "        [0.21090853, 0.9920432 , 0.00161548],\n",
       "        [0.2133818 , 0.99687576, 0.00286076]],\n",
       "\n",
       "       [[0.4752208 , 0.25339046, 0.28054658],\n",
       "        [0.46524593, 0.2509113 , 0.3425306 ],\n",
       "        [0.47978204, 0.2431088 , 0.21844566],\n",
       "        [0.4714977 , 0.24989672, 0.23832138],\n",
       "        [0.488912  , 0.24515305, 0.23566577],\n",
       "        [0.47257054, 0.26575324, 0.28086862],\n",
       "        [0.50861394, 0.25171992, 0.20851749],\n",
       "        [0.46612602, 0.28314623, 0.14674796],\n",
       "        [0.52963513, 0.2615345 , 0.09918719],\n",
       "        [0.47593707, 0.2343562 , 0.11948777],\n",
       "        [0.49268454, 0.23739962, 0.13102852],\n",
       "        [0.4696979 , 0.29001522, 0.0548628 ],\n",
       "        [0.5085553 , 0.28667718, 0.05437632],\n",
       "        [0.50492704, 0.27550063, 0.04243014],\n",
       "        [0.51924753, 0.27353275, 0.04058766],\n",
       "        [0.5223573 , 0.2650606 , 0.07662417],\n",
       "        [0.5236718 , 0.26684853, 0.09988631]]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#visualization\n",
    "keypoints_with_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 17, 3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#visualization\n",
    "keypoints_with_scores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n"
     ]
    }
   ],
   "source": [
    "# Store the extracted foul/nonfoul keypoints in relevant path\n",
    "data = []\n",
    "\n",
    "# for idx, file in enumerate(Path(r\"C:\\Users\\ayesh\\Downloads\\Yaish\\Foul\").rglob(\"*.mp4\"), start = 1):\n",
    "for idx, file in enumerate(Path(r\"C:\\Users\\ayesh\\Downloads\\Yaish\\No Foul\").rglob(\"*.mp4\"), start = 1):\n",
    "#     if idx <= 150:\n",
    "#         continue\n",
    "    \n",
    "    video = []\n",
    "    cap = cv2.VideoCapture(str(file))\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Resize image\n",
    "        img = frame.copy()\n",
    "        img = tf.image.resize_with_pad(tf.expand_dims(img, axis=0), 384,640)\n",
    "        input_img = tf.cast(img, dtype=tf.int32)\n",
    "\n",
    "        # Detection section\n",
    "        results = movenet(input_img)\n",
    "        keypoints_with_scores = results['output_0'].numpy()[:,:2,:51].reshape((2,17,3))\n",
    "        video.append(keypoints_with_scores)\n",
    "        \n",
    "    cap.release()\n",
    "    data.append(np.array(video))\n",
    "    print(idx)\n",
    "    \n",
    "    if idx == 150:\n",
    "        break\n",
    "\n",
    "with open(r\"C:\\Users\\ayesh\\Downloads\\Yaish\\No_Foul.pkl\", \"wb\") as file:\n",
    "    pkl.dump(data,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n",
      "\t=>(45, 2, 17, 3)\n"
     ]
    }
   ],
   "source": [
    "# visualization\n",
    "print(f\"{len(data)}\\n\\t=>{data[0].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 17, 3)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# visualization\n",
    "keypoints_with_scores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
